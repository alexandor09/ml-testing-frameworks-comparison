{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google Colab demo (3–5 min)\n",
        "\n",
        "Этот ноутбук показывает:\n",
        "\n",
        "- где лежат **датасеты** (`data/*.csv`, `data/*.json`)\n",
        "- какие **скрипты** генерируют сценарии с “внедрёнными” проблемами (`generate_scenarios.py`) и запускают проверки (`main.py`, `src/frameworks/*_adapter.py`)\n",
        "- **команду запуска** и где формируются **отчёты/таблицы** (`reports/<run_name>/<timestamp>/...`)\n",
        "- как собрать **mini-table** на test (E_test vs EF_total/EF_true/FP + FalseAlarm) из артефактов:\n",
        "  - `reports/mini_table_E_test.json`\n",
        "  - `reports/mini_table_EF_test.csv`\n",
        "  - `reports/mini_table_final.csv`\n",
        "  - `reports/mini_table_provenance.md`\n",
        "\n",
        "Notes:\n",
        "- **NA** = метрика не формировалась данным средством в текущей конфигурации.\n",
        "- **—** = метрика неприменима (например, Recall при E_test=0; Precision при EF_total=0 или при E_test=0).\n",
        "- `FalseAlarm` используется только когда `E_test=0`: для строковых дефектов это `EF_total / n_test`, для `drift_features` это `EF_total / 3`.\n",
        "\n",
        "Репозиторий: `https://github.com/alexandor09/ml-testing-frameworks-comparison/`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/alexandor09/ml-testing-frameworks-comparison.git\"\n",
        "REPO_DIR = \"ml-testing-frameworks-comparison\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL}\n",
        "\n",
        "%cd {REPO_DIR}\n",
        "!python --version\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Варианты:\n",
        "# - \"light\": ставим минимум для демо одного фреймворка (по умолчанию GX)\n",
        "# - \"full\": ставим всё из requirements.txt (нужно для прогона всех 4 средств + mini-table)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "INSTALL_MODE = \"light\"  # \"light\" | \"full\"\n",
        "\n",
        "if INSTALL_MODE == \"full\":\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"])\n",
        "else:\n",
        "    # main.py импортирует адаптеры лениво, поэтому можно не ставить весь стек.\n",
        "    subprocess.check_call([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "        \"pandas\", \"numpy\", \"prophet\", \"great_expectations\", \"psutil\", \"plotly\", \"scikit-learn\", \"tqdm\",\n",
        "    ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"### data/\")\n",
        "data_dir = Path(\"data\")\n",
        "for p in sorted(data_dir.glob(\"*.csv\")):\n",
        "    print(\"-\", p.as_posix())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Где считаются “внедрённые” и “выявленные” проблемы\n",
        "\n",
        "- **Внедрённые** (ground truth): в `generate_scenarios.py`.\n",
        "  - `pass`: пропуски (`price` ~5%, `y` ~2%) + дубликаты (~3%).\n",
        "  - `dr`: дрейф в **тестовом хвосте** (последние 20%) + выбросы в `y` и `price`.\n",
        "- **Выявленные**: в `src/frameworks/*_adapter.py` через поля `issues_detected` и `check_values`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Быстрый демо-запуск: один фреймворк (GX) на сценарии dr\n",
        "INPUT = \"data/dr.csv\"\n",
        "OUTPUT = \"reports/colab_demo_dr\"\n",
        "FRAMEWORK = \"gx\"  # gx | evidently | alibi | nannyml\n",
        "\n",
        "subprocess.check_call([\n",
        "    sys.executable, \"main.py\",\n",
        "    \"--input\", INPUT,\n",
        "    \"--format\", \"csv\",\n",
        "    \"--output\", OUTPUT,\n",
        "    \"--framework\", FRAMEWORK,\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "run_base = Path(OUTPUT)\n",
        "runs = sorted([p for p in run_base.glob(\"*\") if p.is_dir()])\n",
        "latest = runs[-1]\n",
        "print(\"Latest run:\", latest.as_posix())\n",
        "\n",
        "print(\"\\n### files\")\n",
        "for p in sorted(latest.glob(\"*\") ):\n",
        "    print(\"-\", p.name)\n",
        "\n",
        "summary_path = latest / \"comparison_summary.json\"\n",
        "print(\"\\n### comparison_summary.json\")\n",
        "print(summary_path.as_posix())\n",
        "print(json.dumps(json.loads(summary_path.read_text(encoding=\"utf-8\")), indent=2, ensure_ascii=False)[:4000])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Mini-table build (requires artifacts from runs, so best with INSTALL_MODE=\"full\")\n",
        "# 1) Run scenarios to generate artifacts (ideal/pass/dr)\n",
        "for inp, out in [\n",
        "    (\"data/ideal.csv\", \"reports/run_ideal\"),\n",
        "    (\"data/pass.csv\",  \"reports/run_pass\"),\n",
        "    (\"data/dr.csv\",    \"reports/run_dr\"),\n",
        "]:\n",
        "    subprocess.check_call([\n",
        "        sys.executable, \"main.py\",\n",
        "        \"--input\", inp,\n",
        "        \"--format\", \"csv\",\n",
        "        \"--output\", out,\n",
        "    ])\n",
        "\n",
        "# 2) Build mini-table\n",
        "subprocess.check_call([sys.executable, \"scripts/count_E_test.py\", \"--inputs\", \"data/pass.csv\", \"data/dr.csv\", \"data/ideal.csv\"])\n",
        "subprocess.check_call([sys.executable, \"scripts/count_EF_test.py\"])\n",
        "subprocess.check_call([sys.executable, \"scripts/build_mini_table.py\"])\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\"- reports/mini_table_E_test.json\")\n",
        "print(\"- reports/mini_table_EF_test.csv\")\n",
        "print(\"- reports/mini_table_final.csv\")\n",
        "print(\"- reports/mini_table_provenance.md\")\n",
        "\n",
        "# Show a compact preview of the final table\n",
        "import pandas as pd\n",
        "\n",
        "df_final = pd.read_csv(\"reports/mini_table_final.csv\")\n",
        "display(df_final.head(12))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Опционально) полный прогон со всеми 4 фреймворками и HTML-дашбордом\n",
        "\n",
        "Если хотите получить `dashboard.html` и консольную сравнительную таблицу как в локальном запуске — переключите `INSTALL_MODE = \"full\"` (выше) и выполните ячейку ниже.\n",
        "\n",
        "Далее (после прогонов) можно собрать mini-table скриптами из `scripts/`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FULL RUN (может быть дольше)\n",
        "# - создаст dashboard.html и final_summary.json\n",
        "# - все артефакты будут в reports/colab_demo_full/<timestamp>/\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_FULL = \"data/dr.csv\"\n",
        "OUTPUT_FULL = \"reports/colab_demo_full\"\n",
        "\n",
        "subprocess.check_call([\n",
        "    sys.executable, \"main.py\",\n",
        "    \"--input\", INPUT_FULL,\n",
        "    \"--format\", \"csv\",\n",
        "    \"--output\", OUTPUT_FULL,\n",
        "])\n",
        "\n",
        "run_base = Path(OUTPUT_FULL)\n",
        "runs = sorted([p for p in run_base.glob(\"*\") if p.is_dir()])\n",
        "latest = runs[-1]\n",
        "print(\"Latest full run:\", latest.as_posix())\n",
        "\n",
        "print(\"\\nDashboard:\", (latest / \"dashboard.html\").as_posix())\n",
        "print(\"Final summary:\", (latest / \"final_summary.json\").as_posix())\n",
        "\n",
        "# В Colab самый простой способ посмотреть HTML — скачать файл и открыть локально в браузере.\n",
        "# from google.colab import files\n",
        "# files.download((latest / \"dashboard.html\").as_posix())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mini-table (E_test vs EF_total/EF_true/FP + FalseAlarm)\n",
        "\n",
        "Требует `INSTALL_MODE = \"full\"` (потому что нужны артефакты всех 4 фреймворков).\n",
        "\n",
        "Пайплайн:\n",
        "- запускаем `ideal`, `pass`, `dr` → артефакты в `reports/run_*/<timestamp>/...`\n",
        "- считаем `E_test`, `EF_test`, собираем финальную таблицу\n",
        "\n",
        "Важно:\n",
        "- В итоговой таблице есть `n_test` (контекст размера теста).\n",
        "- **NA** = метрика не формировалась данным средством в текущей конфигурации.\n",
        "- **—** = метрика неприменима (например, Recall при `E_test=0`; Precision при `EF_total=0` или при `E_test=0`).\n",
        "- `FalseAlarm` выводится только когда `E_test=0`:\n",
        "  - для строковых дефектов: `EF_total / n_test`\n",
        "  - для `drift_features`: `EF_total / 3`\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
